{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/scratch/haokang/anaconda3/envs/test/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "def create_model():\n",
    "    # 8bit quant\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/xgen-7b-8k-inst\", trust_remote_code=True, cache_dir = \"./cache/\", device_map=\"auto\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"Salesforce/xgen-7b-8k-inst\", torch_dtype=torch.bfloat16, cache_dir = \"./cache/\", use_cache=True, device_map=\"auto\")\n",
    "    # model = model.half()\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "def create_dataset():\n",
    "    val_dataset = load_dataset(\n",
    "        \"EdinburghNLP/xsum\", split=\"validation\", cache_dir=\"./cache/\"\n",
    "    )\n",
    "    test_dataset = load_dataset(\n",
    "        \"EdinburghNLP/xsum\", split=\"test\", cache_dir=\"./cache/\"\n",
    "    )\n",
    "    return val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:15<00:00,  5.13s/it]\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset, test_dataset = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11120.0\n",
      "11334\n"
     ]
    }
   ],
   "source": [
    "length = 0.0\n",
    "small = 0.0\n",
    "with torch.no_grad():\n",
    "        for i, data in enumerate(test_dataset):\n",
    "            article = data[\"document\"]\n",
    "            if len(article) < 7000:\n",
    "                small += 1\n",
    "                \n",
    "print(small)\n",
    "print(len(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Human: Please summarize the following article.\n",
      "\n",
      "Media playback is unsupported on your device\n",
      "8 May 2015 Last updated at 10:28 BST\n",
      "During the war, families would have to ration their food and had little communication in their homes.\n",
      "Luxuries like chocolate and fruit were very difficult to find and families had to grow their own food to survive.\n",
      "Watch Martin's report to find out more..\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "# model = model.to(\"cuda:0\")\n",
    "# article = \"I am from Japan and My father is a farmer. We live a normal life. My name is John. I am 20 years old. I am a student.\"\n",
    "prompt = f\"### Human: Please summarize the following article.\\n\\n{article}.\\n###\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[21017,  5524,    25,  4222, 35743,   262,  1708,  2708,    13,   198,\n",
      "           198, 13152, 16388,   318, 24222,   319,   534,  3335,   198,    23,\n",
      "          1737,  1853,  4586,  6153,   379,   838,    25,  2078, 44992,   198,\n",
      "          7191,   262,  1175,    11,  4172,   561,   423,   284, 36535,   511,\n",
      "          2057,   290,   550,  1310,  6946,   287,   511,  5682,    13,   198,\n",
      "            43,  2821,  4740,   588, 11311,   290,  8234,   547,   845,  2408,\n",
      "           284,  1064,   290,  4172,   550,   284,  1663,   511,   898,  2057,\n",
      "           284,  7866,    13,   198, 10723,  5780,   338,   989,   284,  1064,\n",
      "           503,   517,   492,   198, 21017]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/hkang342/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "/nethome/hkang342/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1535: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sample = model.generate(**inputs, do_sample=True, max_new_tokens=2048, top_k=100, eos_token_id=50256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n"
     ]
    }
   ],
   "source": [
    "output = tokenizer.decode(sample[0])\n",
    "print(output.strip().replace(\"Assistant:\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Human: Please summarize the following article.\n",
      "\n",
      "Media playback is unsupported on your device\n",
      "8 May 2015 Last updated at 10:28 BST\n",
      "During the war, families would have to ration their food and had little communication in their homes.\n",
      "Luxuries like chocolate and fruit were very difficult to find and families had to grow their own food to survive.\n",
      "Watch Martin's report to find out more..\n",
      "### Assistant: The article is about how families during World War 2 had to ration their food and grow their own food to survive, as luxuries like chocolate and fruit were difficult to find. The reporter, Martin, explains the challenges of life during the war and how families had to adapt to survive.\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
