python3 test_gsm8k.py --model_name_or_path mistralai/Mistral-7B-v0.1  --batch_size 40 --device_map "cuda:0" --gpu 0 > mistral_gsm8k_benchmark.txt


python3 test_gsm8k.py --model_name_or_path mistralai/Mistral-7B-v0.1  --batch_size 40 --device_map "cuda:0" --gpu 0 --compress_method densesparseuniformquantization --attention_number 40 --quantize_bit 4 --left 0.05 --streaming --streaming_gap 20 > mistral_gsm8k_outlier_4_0.05.txt
python3 test_gsm8k.py --model_name_or_path mistralai/Mistral-7B-v0.1  --batch_size 40 --device_map "cuda:0" --gpu 0 --compress_method densesparseuniformquantization --attention_number 40 --quantize_bit 4 --left 0.01 --streaming --streaming_gap 20 > mistral_gsm8k_outlier_4_0.01.txt
python3 test_gsm8k.py --model_name_or_path mistralai/Mistral-7B-v0.1  --batch_size 40 --device_map "cuda:0" --gpu 0 --compress_method densesparseuniformquantization --attention_number 40 --quantize_bit 4 --left 0.02 --streaming --streaming_gap 20 > mistral_gsm8k_outlier_4_0.02.txt
python3 test_gsm8k.py --model_name_or_path mistralai/Mistral-7B-v0.1  --batch_size 40 --device_map "cuda:0" --gpu 0 --compress_method densesparseuniformquantization --attention_number 40 --quantize_bit 4 --left 0.10 --streaming --streaming_gap 20 > mistral_gsm8k_outlier_4_0.10.txt


python test_gsm8k.py --model mistralai/Mistral-7B-v0.1  --batch_size 40  --compress_method outquantize_with_lrap --attention_number 40 --quantize_bit 4 --left 0.05 --rank 0.05 --rankv 0.05 --loop 3 --streaming --streaming_gap 20 > mistral_outquantwithlrap_4b_l0.05_r0.05.txt
python test_gsm8k.py --model mistralai/Mistral-7B-v0.1  --batch_size 40  --compress_method outquantize_with_lrap --attention_number 40 --quantize_bit 4 --left 0.05 --rank 0.02 --rankv 0.02 --loop 3 --streaming --streaming_gap 20 > mistral_outquantwithlrap_4b_l0.05_r0.02.txt
python test_gsm8k.py --model mistralai/Mistral-7B-v0.1  --batch_size 40  --compress_method outquantize_with_lrap --attention_number 40 --quantize_bit 4 --left 0.02 --rank 0.02 --rankv 0.05 --loop 2 --streaming --streaming_gap 20 > mistral_outquantwithlrap_4b_l0.02_r0.02.txt
python test_gsm8k.py --model mistralai/Mistral-7B-v0.1  --batch_size 40  --compress_method outquantize_with_lrap --attention_number 40 --quantize_bit 4 --left 0.01 --rank 0.05 --rankv 0.05 --loop 3 --streaming --streaming_gap 20 > mistral_outquantwithlrap_4b_l0.01_r0.05.txt
python test_gsm8k.py --model mistralai/Mistral-7B-v0.1  --batch_size 40  --compress_method outquantize_with_lrap --attention_number 40 --quantize_bit 4 --left 0.01 --rank 0.02 --rankv 0.02 --loop 3 --streaming --streaming_gap 20 > mistral_outquantwithlrap_4b_l0.01_r0.02.txt

python3 test_gsm8k.py --model_name_or_path mistralai/Mistral-7B-v0.1  --batch_size 40 --device_map "cuda:0" --gpu 0 --compress_method densesparseuniformquantization --attention_number 40 --quantize_bit 6 --left 0.05 --streaming --streaming_gap 20 > mistral_gsm8k_outlier_6_0.05.txt
python3 test_gsm8k.py --model_name_or_path mistralai/Mistral-7B-v0.1  --batch_size 40 --device_map "cuda:0" --gpu 0 --compress_method densesparseuniformquantization --attention_number 40 --quantize_bit 6 --left 0.01 --streaming --streaming_gap 20 > mistral_gsm8k_outlier_6_0.01.txt
python3 test_gsm8k.py --model_name_or_path mistralai/Mistral-7B-v0.1  --batch_size 40 --device_map "cuda:0" --gpu 0 --compress_method densesparseuniformquantization --attention_number 40 --quantize_bit 6 --left 0.02 --streaming --streaming_gap 20 > mistral_gsm8k_outlier_6_0.02.txt
python3 test_gsm8k.py --model_name_or_path mistralai/Mistral-7B-v0.1  --batch_size 40 --device_map "cuda:0" --gpu 0 --compress_method densesparseuniformquantization --attention_number 40 --quantize_bit 6 --left 0.10 --streaming --streaming_gap 20 > mistral_gsm8k_outlier_6_0.10.txt