python eval_gsm8k_cot.py --model TheBloke/Nous-Hermes-Llama-2-7B-GPTQ --prompt_file prompt_original.txt --batch_size 2 --max_new_tokens 256 --weight-compress GPTQ > llama_2_gptq8.test